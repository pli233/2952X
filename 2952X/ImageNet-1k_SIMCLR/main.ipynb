{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# SimCLR on ImageNet 1K: Pretrained Model Evaluation and Ablation Study\n",
    "\n",
    "This project evaluates the performance of a pretrained SimCLR model on the ImageNet 1K dataset. It also explores various ablation studies to understand the impact of different components and hyperparameters on the model's accuracy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae810d165c755ee",
   "metadata": {},
   "source": [
    "## 0.Import Packages and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T18:00:01.637475Z",
     "start_time": "2024-10-25T18:00:01.622206Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models.modules import SimCLRProjectionHead\n",
    "from lightly.transforms.simclr_transform import SimCLRTransform\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "\n",
    "# Load the YAML file\n",
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "SCDD_DATASET_PATH = config[\"data_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5273e91543fdd2f",
   "metadata": {},
   "source": [
    "## 1.Load Distilled Data With Customized Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ba07cead341545",
   "metadata": {},
   "source": [
    "### 1.1 Define the Distilled SCDD Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a61a551712dca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T02:22:51.179624Z",
     "start_time": "2024-10-25T02:22:51.163096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset definition\n",
    "class SCDDImageNetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom Dataset class for loading the SCDD-ImageNet dataset.\n",
    "\n",
    "    The dataset is organized into folders where each folder corresponds to a class (e.g., new000, new001),\n",
    "    and each folder contains images belonging to that class.\n",
    "\n",
    "    Args:\n",
    "        root_dir (string): The root directory containing the dataset folders.\n",
    "        transform (callable, optional): A transform to be applied to the images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = []  # List to store all image file paths\n",
    "        self.labels = []  # List to store labels corresponding to images\n",
    "        self.classes = []  # List to store class names (folders)\n",
    "        \n",
    "        if transform == None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),  # Resize images to 224x224 (commonly used for ImageNet)\n",
    "                transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "            ])  # Convert images to tensors\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        self._prepare_dataset()\n",
    "\n",
    "    def _prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        Traverse the root directory to gather all image file paths and their corresponding labels.\n",
    "        The folder name is used as the class label.\n",
    "        \"\"\"\n",
    "        for label_folder in os.listdir(self.root_dir):\n",
    "            label_folder_path = os.path.join(self.root_dir, label_folder)\n",
    "            if os.path.isdir(label_folder_path):\n",
    "                self.classes.append(label_folder)\n",
    "                for img_file in os.listdir(label_folder_path):\n",
    "                    if img_file.endswith('.jpg'):  # Process only .jpg files\n",
    "                        img_path = os.path.join(label_folder_path, img_file)\n",
    "                        self.image_paths.append(img_path)\n",
    "                        self.labels.append(label_folder)  # Folder name is the label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the image to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            image (Tensor): Transformed image.\n",
    "            label (str): Corresponding label (class name).\n",
    "        \"\"\"\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Open the image and convert to RGB\n",
    "        \n",
    "         # Convert the image to a tensor\n",
    "        image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42b3a6e",
   "metadata": {},
   "source": [
    "### 1.2 Test the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SCDDImageNetDataset(root_dir=SCDD_DATASET_PATH)\n",
    "\n",
    "# Create a DataLoader to load a small batch\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Iterate over the DataLoader to get a single batch\n",
    "for images, labels in dataloader:\n",
    "    print(f\"Batch of images: {images}\")\n",
    "    print(f\"Batch of labels: {labels}\")\n",
    "    break  # Only load one batch for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b433a6f7ccfe8",
   "metadata": {},
   "source": [
    "### 1.2 Test Functions with Small Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0a8e8d2a0d6c7",
   "metadata": {},
   "source": [
    "## Model Definition: SIMCLR WITH ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4fc1d0d51ab68b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T02:35:05.713914Z",
     "start_time": "2024-10-25T02:35:05.709879Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = SimCLRProjectionHead(512, 512, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(x)\n",
    "        return z\n",
    "#Test the definition of SimCLR works\n",
    "resnet = torchvision.models.resnet18()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "model = SimCLR(backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014a40bf9b02bc0",
   "metadata": {},
   "source": [
    "## 3.Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d0823b755b3a9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-25T02:12:33.388333Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_ImageNet_SimCLR(config):\n",
    "    # Load settings from the config file\n",
    "    SCDD_DATASET_PATH = config[\"data_path\"]\n",
    "    SCDD_BATCH_SIZE = config[\"batch_size\"]\n",
    "    SCDD_NUM_WORKERS = config[\"num_workers\"]\n",
    "    SCDD_EPOCHS = config[\"epochs\"]\n",
    "    SCDD_LEARNING_RATE = config[\"learning_rate\"]\n",
    "    SCDD_SAVE_PATH = config[\"save_path\"]\n",
    "    SCDD_Pretrain_Resnet = config[\"pretrain_resnet\"]\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() and not config[\"disable_cuda\"] else 'cpu')\n",
    "\n",
    "    # Print out all training parameters\n",
    "    print(\"Training Parameters:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Print the device being used\n",
    "    if DEVICE.type == 'cuda':\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"Training on device: {gpu_name}\")  # Print GPU name\n",
    "    else:\n",
    "        gpu_name = \"CPU\"\n",
    "        print(\"Training on CPU\")\n",
    "\n",
    "    # Create a unique directory for this run based on timestamp and GPU name\n",
    "    run_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_directory = f\"{SCDD_SAVE_PATH}/run_{run_timestamp}_{gpu_name.replace(' ', '_')}\"\n",
    "    os.makedirs(run_directory, exist_ok=True)\n",
    "\n",
    "    #Save config to the run dir\n",
    "    config_file_path = os.path.join(run_directory, \"config.txt\")\n",
    "    with open(config_file_path, \"w\") as f:\n",
    "        for key, value in config.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    print(f\"Configuration saved to {config_file_path}\")\n",
    "    \n",
    "    # Load the model and send to device\n",
    "    resnet = torchvision.models.resnet18(pretrained=SCDD_Pretrain_Resnet)\n",
    "    backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "    model = SimCLR(backbone)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Prepare the dataset and dataloader\n",
    "    transform = SimCLRTransform(input_size=224)  # Adjust the input size for ImageNet\n",
    "    scdd_dataset = SCDDImageNetDataset(root_dir=SCDD_DATASET_PATH, transform=transform)\n",
    "\n",
    "    scdd_dataloader = DataLoader(\n",
    "        scdd_dataset,\n",
    "        batch_size=SCDD_BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=SCDD_NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "    # Set up the criterion and optimizer\n",
    "    criterion = NTXentLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=SCDD_LEARNING_RATE)\n",
    "\n",
    "    # Variables to track the best model\n",
    "    best_loss = float('inf')\n",
    "    best_checkpoint_path = os.path.join(run_directory, \"best_checkpoint.pth\")\n",
    "\n",
    "    # Training Loop\n",
    "    print(\"Starting Training\")\n",
    "    for epoch in range(SCDD_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Progress bar setup\n",
    "        progress_bar = tqdm(enumerate(scdd_dataloader), total=len(scdd_dataloader), desc=f\"Epoch {epoch + 1}/{SCDD_EPOCHS}\")\n",
    "\n",
    "        for i, batch in progress_bar:\n",
    "            # Get batch data\n",
    "            x0, x1 = batch[0]\n",
    "            x0 = x0.to(DEVICE)\n",
    "            x1 = x1.to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            z0 = model(x0)\n",
    "            z1 = model(x1)\n",
    "            loss = criterion(z0, z1)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Update the progress bar\n",
    "            avg_loss = total_loss / (i + 1)\n",
    "            progress_bar.set_postfix(loss=avg_loss)\n",
    "\n",
    "        # Print epoch loss\n",
    "        print(f\"Epoch {epoch + 1}/{SCDD_EPOCHS}, Average Loss: {avg_loss:.5f}\")\n",
    "\n",
    "        # Save the model checkpoint for the current epoch\n",
    "        epoch_checkpoint_path = os.path.join(run_directory, f\"simclr_epoch_{epoch + 1}.pth\")\n",
    "        torch.save(model.state_dict(), epoch_checkpoint_path)\n",
    "        print(f\"Model saved to {epoch_checkpoint_path}\")\n",
    "\n",
    "        # Save the latest checkpoint (overwrite each epoch)\n",
    "        latest_checkpoint_path = os.path.join(run_directory, \"latest_checkpoint.pth\")\n",
    "        torch.save(model.state_dict(), latest_checkpoint_path)\n",
    "        print(f\"Latest model checkpoint updated at {latest_checkpoint_path}\")\n",
    "\n",
    "        # Check if this is the best model so far and save it separately\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), best_checkpoint_path)\n",
    "            print(f\"New best model saved to {best_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe83e538bd3835",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ImageNet_SimCLR(config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
